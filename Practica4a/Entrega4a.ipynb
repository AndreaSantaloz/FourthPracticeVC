{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e52a77",
   "metadata": {},
   "source": [
    "# Entrega de práctica 4a\n",
    "------------------------------\n",
    "## Autores\n",
    "1. Andrea Santana López"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b370f3",
   "metadata": {},
   "source": [
    "## ¿En qué consiste la prática?\n",
    "Consiste en cojer un video y detectar objetos como coches,personas,matriculas,es decir elementos en la calle.Utilizaremos la librería de python YOLO para su realización.\n",
    "\n",
    "Los pasos son simples:\n",
    "\n",
    "1. Convertir el video a imagenes separadas\n",
    "2. Guardarlas en una carpeta en nuestro caso esta carpeta estará almacenada en ./Practica4a/images\n",
    "3. Por cada imágen guardada hay que crear una caja delimitadora(bounding box) y asignarle etiquetas que se puede usar LabelLing,CVAT o Roboflow\n",
    "4. A partir de aquí es realizar un YAML de donde aprenderá\n",
    "5. Se entrenará el modelo con el YAML que hemos creado el cual generará un fichero.\n",
    "6. Cojemos este fichero y realizamos la predición con el modelo para ver cuantos objetos detecta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25fcbd",
   "metadata": {},
   "source": [
    "### Paso cero importar librerias a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084e46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb16520",
   "metadata": {},
   "source": [
    "### Primer paso convertir video a imágenes separadas y Segundo guardarlas en una carpeta en nuestro caso esta carpeta estará almacenada en ./Practica4a/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba25f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andsa\\Documents\\202526ULPGC\\VC\\FourthPracticeVC\\Practica4a\\images\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "base_dir = Path.cwd()\n",
    "ruta_de_imagenes = base_dir / \"images\"\n",
    "print(ruta_de_imagenes)\n",
    "\n",
    "ruta_relativa_completa = base_dir / \"video1.mp4\"\n",
    "ruta_final = str(ruta_relativa_completa)\n",
    "capture_video = cv2.VideoCapture(ruta_final)\n",
    "\n",
    "frame_count = 0\n",
    "limite_fotogramas_roboflow = 10\n",
    "frame_skip = 30\n",
    "\n",
    "if not capture_video.isOpened():\n",
    "    print(\"No existe ningun video en esa ruta\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture_video.read()\n",
    "    if not ret:\n",
    "        print(\"No puede recibir frame\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if frame_count % frame_skip == 0 and frame_count // frame_skip < limite_fotogramas_roboflow:\n",
    "        filename = f\"frame_{frame_count:05d}.jpg\"\n",
    "        full_output_path = ruta_de_imagenes / filename\n",
    "        cv2.imwrite(str(full_output_path), frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0941dac",
   "metadata": {},
   "source": [
    "Tercero por cada imágen guardada hay que crear una caja delimitadora(bounding box) y asignarle etiquetas que se puede usar LabelLing,CVAT o Roboflow.\n",
    "En nuestro caso escogimos roboflow donde le dijimos que detectara: personas,bicicletas,semaforos y personas.\n",
    "\n",
    "Roboflow nos dice que en función del lenguaje hagamos los siguientes pasos:\n",
    "1. pip install inference-sdk\n",
    "2. Pegaramos el siguiente código\n",
    "```\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "client = InferenceHTTPClient(\n",
    "    api_url=\"https://serverless.roboflow.com\",\n",
    "    api_key=\"vim6cujDQMZU9unOVcYT\"\n",
    ")\n",
    "\n",
    "result = client.run_workflow(\n",
    "    workspace_name=\"detectobjects-3u9en\",\n",
    "    workflow_id=\"find-trafficlights-cars-people-bicycles-and-buildings\",\n",
    "    images={\n",
    "        \"image\": \"YOUR_IMAGE.jpg\"\n",
    "    },\n",
    "    use_cache=True # cache workflow definition for 15 minutes\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91926ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "client = InferenceHTTPClient(\n",
    "    api_url=\"https://serverless.roboflow.com\",\n",
    "    api_key=\"vim6cujDQMZU9unOVcYT\"\n",
    ")\n",
    "\n",
    "result = client.run_workflow(\n",
    "    workspace_name=\"detectobjects-3u9en\",\n",
    "    workflow_id=\"find-trafficlights-cars-people-bicycles-and-buildings\",\n",
    "    images={\n",
    "        \"image\": \"YOUR_IMAGE.jpg\"\n",
    "    },\n",
    "    use_cache=True # cache workflow definition for 15 minutes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f7a88",
   "metadata": {},
   "source": [
    "## 4. A partir de aquí es realizar un YAML de donde aprenderá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ad987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
